#+TITLE: Report of TOP Project
#+AUTHOR: Bouton Nicolas
#+DATE: April 2021

* Debugging
** Multiple definition

   For beginnig the code have a link problem at the compile time because we
   define 3 variables in *lbm_phys.h* and we redefine them in *lbm_phys.h*. Then
   we have a multiple definition.

   #+BEGIN_SRC shell
[148] [sholde@ground simu_simple_LBM] (master) (6m32s) $ make
mpicc -Wall -g -c -o main.o main.c
mpicc -Wall -g -c -o lbm_phys.o lbm_phys.c
mpicc -Wall -g -c -o lbm_init.o lbm_init.c
mpicc -Wall -g -c -o lbm_struct.o lbm_struct.c
mpicc -Wall -g -c -o lbm_comm.o lbm_comm.c
mpicc -Wall -g -c -o lbm_config.o lbm_config.c
mpicc -Wall -g -o lbm main.o lbm_phys.o lbm_init.o lbm_struct.o lbm_comm.o lbm_config.o -lm
/usr/bin/ld : lbm_phys.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:9 : définitions multiples de « opposite_of »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:9 : défini pour la première fois ici
/usr/bin/ld : lbm_phys.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:10 : définitions multiples de « equil_weight »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:10 : défini pour la première fois ici
/usr/bin/ld : lbm_phys.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:11 : définitions multiples de « direction_matrix »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:11 : défini pour la première fois ici
/usr/bin/ld : lbm_init.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:9 : définitions multiples de « opposite_of »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:9 : défini pour la première fois ici
/usr/bin/ld : lbm_init.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:10 : définitions multiples de « equil_weight »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:10 : défini pour la première fois ici
/usr/bin/ld : lbm_init.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:11 : définitions multiples de « direction_matrix »; main.o:/home/sholde/dev/master/M1/S2/hm/top_project/simu_simple_LBM/lbm_phys.h:11 : défini pour la première fois ici
collect2: erreur: ld a retourné le statut de sortie 1
make: *** [Makefile:24 : lbm] Erreur 1
   #+END_SRC

   To fix the problem we just need to mark these variable extern in header file
   to indicate they are define in another file.

   #+BEGIN_SRC c
/********************** CONSTS **********************/
extern const int opposite_of[DIRECTIONS];
extern const double equil_weight[DIRECTIONS];
extern const Vector direction_matrix[DIRECTIONS];
   #+END_SRC

** Program doesn't give back and abort sometimes

   When we execute the code now, with the command ~mpirun -np 512
   --oversubscribe ./lbm~, thr program doesn't give back.

   I decide to run *gdb* and try to identify where we block. And *gdb* say me
   that I have a *segfault* in the function
   *setup_init_state_global_poiseuille_profile* in file *lbm_init.c* at line 85.

   This line contain the result of a call fonction. But as the *segfault* is in
   this function, it is not in the call funtion. Therefore it is the affectaion
   the error and either the array are not allocate or we go out of the limit of
   our array.

   When I reading the code I saw in the init function that malloc call was
   commented. I decomment it and the error is corrected.

** Program doesn't give back and abort sometimes 2

   I re-run *gdb* and it says me that I have a *segfault* when I call the
   *libc*. It is true because an allocation via *malloc* failed (printed in
   stdout).
   
   #+BEGIN_SRC shell
malloc: Permission denied
   #+END_SRC

   The problem was that I don't realize we set address of the last problem to
   *NULL* after we allocate it. I deleted the line.

   #+BEGIN_SRC c
mesh->cell = NULL;
   #+END_SRC
** Run the program

   Then I run the program with a reduce number of iteration (16) and without
   *MPI*. The program finish without crashing.

   I decide to run it with *MPI* but it doesn't give back again and doesn't
   print on standart output anything. I decide to inspect the code and find an
   error of communication maybe.

   The problem is that on the *main* function, we autorize only the
   *RANK_MASTER* process to execute the function *close_file*. But in this
   function we have a *MPI* barrier with *MPI_COMM_WORLD* that wait all
   process. And the problem is that others threads haven't a *MPI* barrier. Thus
   the *RANK_MASTER* wait infinitely.

   To patch this, I remove the line of *MPI* barrier in *close_file* function.

** Valgrind

   I decide to run *valgrind* now, but it seems to be normal. We haven't
   *possbilby lost* or *suppressed* bytes. But we have *833 bytes definitely
   lost*.

   #+BEGIN_SRC json
==29527== HEAP SUMMARY:
==29527==     in use at exit: 83,271 bytes in 50 blocks
==29527==   total heap usage: 21,807 allocs, 21,757 frees, 33,251,263 bytes allocated
==29527== 
==29527== LEAK SUMMARY:
==29527==    definitely lost: 833 bytes in 12 blocks
==29527==    indirectly lost: 599 bytes in 20 blocks
==29527==      possibly lost: 0 bytes in 0 blocks
==29527==    still reachable: 81,839 bytes in 18 blocks
==29527==         suppressed: 0 bytes in 0 blocks
   #+END_SRC

   Therfore I will check the code to see where memory is not release. But
   everything seems ok, I zap this part.

* Original Code
** Result

   Fist of all, I want to execute the code and generate a *gif* to see if it
   working. This is the last frame (frame 4 of 4):

   #+CAPTION: Last frame of Origin Code
   #+NAME: fig:last_frame_of_origin_code
   #+ATTR_LATEX: :width 300px
   [[./simu_simple_LBM/origin_code_last_frame.png]]

   It is not like the image in the subject. So I will investigate the code and
   see what is wrong. But for the moment I will zap this part.

** GIF, Image and script

   Also I have only *4* frame when I run your script. And an error occur:

   #+BEGIN_SRC shell
gnuplot> splot "< ./display --gnuplot result.raw 4" u 1:2:4
                                                           ^
         line 0: All points x value undefined
   #+END_SRC

   But the srcipt generate the *gif*

** Checksum Script

   I make a script which call *display* binary with the 2 file and the number of
   frame in parameter to compare their checksum.

** Communication
*** Explaination

    Fistr of all I reduce the number of iteration from *1600* to *16* and the
    number of processus *MPI* from *512* to *4*. Because it was too long to
    test.

    I am workeing on a personnal project of *MPI profiler* and for a number of
    *4* process and the following configuration:

    #+BEGIN_SRC shell
=================== CONFIG ===================
iterations           = 10
width                = 800
height               = 160
obstacle_r           = 17.000000
obstacle_x           = 161.000000
obstacle_y           = 83.000000
reynolds             = 100.000000
reynolds             = 100.000000
inflow_max_velocity  = 0.100000
output_filename      = resultat.raw
write_interval       = 50
------------ Derived parameters --------------
kinetic_viscosity    = 0.034000
relax_parameter      = 1.661130
==============================================
    #+END_SRC

    I obtain that:

    #+BEGIN_SRC shell
===============================================================================
================================= MPI PROFILER ================================
===============================================================================
GLOBAL SUMMARY:
        388317 message send
        388317 message recv
        436 barrier passed

LOCAL SUMMARY (Process 0):
        64719 message send [ 1 ]
        64722 message recv [ 1 2 3 ]
        109 barrier passed

LOCAL SUMMARY (Process 1):
        129439 message send [ 0 2 ]
        129438 message recv [ 0 2 ]
        109 barrier passed

LOCAL SUMMARY (Process 2):
        129439 message send [ 0 1 3 ]
        129438 message recv [ 1 3 ]
        109 barrier passed

LOCAL SUMMARY (Process 3):
        64720 message send [ 0 2 ]
        64719 message recv [ 2 ]
        109 barrier passed

ERROR SUMMARY:
        No error
    #+END_SRC

    For the moment, it is just an interposition library that interpose
    *MPI_Send*, *MPI_Recv* and *MPI_Barrier*.

    We can see that we have a lot of communication, and a lot of barrier. We can
    see that also in the code bacause we loop on *MPI_Send*, *MPI_Recv* and
    *MPI_Barrier* call.

    For the communication, if we consider that all process send their info to
    master process (process 0) for print information. We can see that the
    communication for *4* MPI process are the following:

    - each process communicate with his neighbors

      
    The code of my *MPI Profiler* will be added to my github this week. For the
    moment we need to preload manually the library with *LD_PRELOAD*.

    https://github.com/Sholde

    Here with *8* processus to confirm the communication scheme:

    #+BEGIN_SRC shell
===============================================================================
================================= MPI PROFILER ================================
===============================================================================
GLOBAL SUMMARY:
        906073 message send
        906073 message recv
        872 barrier passed

LOCAL SUMMARY (Process 0):
        64719 message send [ 1 ]
        64726 message recv [ 1 2 3 4 5 6 7 ]
        109 barrier passed

LOCAL SUMMARY (Process 1):
        129439 message send [ 0 2 ]
        129438 message recv [ 0 2 ]
        109 barrier passed

LOCAL SUMMARY (Process 2):
        129439 message send [ 0 1 3 ]
        129438 message recv [ 1 3 ]
        109 barrier passed

LOCAL SUMMARY (Process 3):
        129439 message send [ 0 2 4 ]
        129438 message recv [ 2 4 ]
        109 barrier passed

LOCAL SUMMARY (Process 4):
        129439 message send [ 0 3 5 ]
        129438 message recv [ 3 5 ]
        109 barrier passed

LOCAL SUMMARY (Process 5):
        129439 message send [ 0 4 6 ]
        129438 message recv [ 4 6 ]
        109 barrier passed

LOCAL SUMMARY (Process 6):
        129439 message send [ 0 5 7 ]
        129438 message recv [ 5 7 ]
        109 barrier passed

LOCAL SUMMARY (Process 7):
        64720 message send [ 0 6 ]
        64719 message recv [ 6 ]
        109 barrier passed

ERROR SUMMARY:
        No error
        #+END_SRC

        So it is not the scheme describe in the subject were we have a cube, and
        we can exchange in diagonally, and vertically. Here we exchange only
        horizontally.

        But on the code, we exchange vetically and diagonally, so I don't know
        why we don't exchange. Maybe the initialisation was not correct.

*** Scheme
   
    #+CAPTION: Scheme of Original Code
    #+NAME: fig:scheme_of_original_code
    #+ATTR_LATEX: :width 300px
    [[./ressources/scheme_of_original_code.png]]
** Scalability of Original Code

   I added few lines to compute the times of the code with *MPI_Wtime*.
